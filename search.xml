<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>My CV</title>
    <url>/2024/06/23/Xiao-Chris-Zheng/</url>
    <content><![CDATA[<!-- Hi! My name is Xiao Zheng, a final-year PhD candidate in Engineering and IT at the University of Melbourne. My research is about developing Machine Learning/Deep Learning solutions for traffic forecasting. 

I am passionate about pushing the boundaries of current frameworks and am always open to collaborating with data science and industry professionals to explore innovative solutions.

**Currently, I am transitioning my career towards the industry and application domains, and have decided to launch a blog to track my journey.** -->

<h1 id="Xiao-Chris-Zheng"><a href="#Xiao-Chris-Zheng" class="headerlink" title="Xiao (Chris) Zheng"></a><strong>Xiao (Chris) Zheng</strong></h1><p>üìç Melbourne, Australia ‚Ä¢ ‚úâÔ∏è <a href="mailto:xiaozheng.chris@gmail.com">xiao[my surname].chris[at]gmail.com</a> </p>
<h1 id="Professional-Profile"><a href="#Professional-Profile" class="headerlink" title="Professional Profile"></a><strong>Professional Profile</strong></h1><p><strong>Core Competencies: Machine Learning | Data Science | Analysis &amp; Modelling Skills | Research Skills | Stakeholder Consultation | Reports &amp; Presentations Preparation</strong></p>
<p>A PhD researcher in Machine Learning and Transport Engineering at the University of Melbourne, with over 3 years of experience in developing and implementing state-of-the-art Machine Learning&#x2F;Deep Learning methods for structured and unstructured data. Obtained a Master of Engineering (Civil) and 2 years of local working experience as a consulting engineer.  </p>
<p>I am passionate about pushing the boundaries of current frameworks and am always open to collaborating with data science and industry professionals to explore innovative solutions.</p>
<hr>
<h1 id="Research-Projects"><a href="#Research-Projects" class="headerlink" title="Research Projects"></a><strong>Research Projects</strong></h1><span id="more"></span>

<ul>
<li>Developed and evaluated Transformer-based, RNN-based, and ensemble learning methods for long-term traffic forecasting using large real-world datasets.</li>
<li>Created a framework (TRECK) for representation learning utilising contrastive learning, entity embedding, and a multi-task joint learning paradigm. This framework outperforms hand-crafted features for long-term traffic forecasting, enabling a basic BiLSTM model to exceed state-of-the-art Transformer-based methods by 57.76%.</li>
<li>Assessed various Machine Learning interpretation techniques, including <strong>Permutation Feature Importance</strong>, <strong>SHAP</strong>, and <strong>Accumulated Local Effects plots</strong>.</li>
<li>Developed a memory mechanism with Variational AutoEncoder (RecVAE). The resulting hybrid method with GBRT achieves competitive results on 4 real-world time series datasets. <a href="https://github.com/xiaozheng7/RecVAE-GBRT">GitHub Repository</a>  </li>
<li>Investigated solutions for uncertainty quantification in predictive models.</li>
</ul>
<hr>
<h1 id="Education"><a href="#Education" class="headerlink" title="Education"></a><strong>Education</strong></h1><p><strong>PhD Candidate (Engineering and IT)</strong><br><a href="https://www.unimelb.edu.au/">UNIVERSITY OF MELBOURNE</a>, Melbourne, VIC<br><em>Expected Thesis Submission: August 2024</em>  </p>
<ul>
<li><strong>Honors</strong>: John H. Taplin Award for the best paper at The Australasian Transport Research Forum (ATRF) 2022.</li>
</ul>
<p><strong>Master of Engineering (Civil)</strong><br><a href="https://www.unimelb.edu.au/">UNIVERSITY OF MELBOURNE</a>, Melbourne, VIC<br><em>Graduated: July 2018</em>  </p>
<ul>
<li><strong>WAM</strong>: 85.75 &#x2F; 100</li>
<li><strong>Honors</strong>: Dean‚Äôs Honours List (top 5%) - Melbourne School of Engineering - Awarded in 2018 and 2017.</li>
</ul>
<p><strong>Bachelor of Civil Engineering</strong><br><a href="https://www.whut.edu.cn/">WUHAN UNIVERSITY OF TECHNOLOGY</a>, Wuhan, China<br><em>Graduated: July 2016</em>  </p>
<ul>
<li><strong>GPA</strong>: 3.58 &#x2F; 4.0</li>
</ul>
<hr>
<h1 id="Professional-Experience"><a href="#Professional-Experience" class="headerlink" title="Professional Experience"></a><strong>Professional Experience</strong></h1><p><strong>Research Assistant (Casual)</strong><br><a href="https://www.unimelb.edu.au/">UNIVERSITY OF MELBOURNE</a>, Melbourne, VIC<br><em>2023 ‚Äì 2024</em> </p>
<ul>
<li>Collaborating closely with data scientists and engineers to perform comprehensive data analysis and implement Deep Learning solutions for the <a href="https://eng.unimelb.edu.au/industry/aimes">Australian Integrated Multimodal EcoSystem (AIMES)</a>. </li>
<li>Developed several efficient Python frameworks for integrating multi-source data into simulation software and facilitating the smooth flow of data between the software and Deep Learning models.</li>
<li>Conducted crowd simulation for major projects worldwide, encompassing model development, stakeholder presentations, and the preparation of technical reports to communicate findings.</li>
</ul>
<p><strong>Engineering Consultant</strong><br><a href="http://rapidengineers.com.au/">RAPID CONSULTING ENGINEERS PTY LTD</a>, Melbourne, VIC<br><em>2019 ‚Äì 2020</em> </p>
<ul>
<li>Conducting advanced non-destructive and destructive testing to landmark infrastructural and commercial projects across Australia, including designing tailored testing programs, organising and analysing testing results, and formalising reports. </li>
<li>Conducting design and structural analysis for residential, commercial, and industrial projects.</li>
<li>Directly engaging with clients throughout project lifecycles to ensure alignment with objectives and deliverables.</li>
<li>Involvement in business development, feasibility investigation and formalisation of fee proposals.</li>
</ul>
<p><strong>Tutor (Casual)</strong><br><a href="https://linghang.education/">NAVIGATION INTERNATIONAL PTY LTD</a>, Melbourne, VIC<br><em>2018 ‚Äì 2020</em>  </p>
<ul>
<li>Giving lectures on several university courses, including Calculus, Linear Algebra, Engineering Mathematics, Systems Modelling and Design, and Engineering Mechanics.</li>
<li>Preparing and improving teaching programmes and teaching materials.</li>
</ul>
<hr>
<h1 id="Skills"><a href="#Skills" class="headerlink" title="Skills"></a><strong>Skills</strong></h1><ul>
<li><strong>Programming Languages</strong>: <img src="https://img.shields.io/badge/-Python-blue" alt="Python"><img src="https://img.shields.io/badge/-SQL-lightgrey" alt="SQL"></li>
<li><strong>Frameworks &amp; Tools</strong>: <img src="https://img.shields.io/badge/-Scikit--Learn-blue" alt="Scikit-Learn"><img src="https://img.shields.io/badge/-PyTorch-red" alt="PyTorch"><img src="https://img.shields.io/badge/-NumPy-blue" alt="NumPy"><img src="https://img.shields.io/badge/-Pandas-green" alt="Pandas"><img src="https://img.shields.io/badge/-GeoPandas-lightblue" alt="GeoPandas"></li>
<li><strong>Cloud Platforms</strong>: <img src="https://img.shields.io/badge/-AWS-orange" alt="AWS"><img src="https://img.shields.io/badge/-Azure-blueviolet" alt="Azure"></li>
<li><strong>Analytical and Modelling Software</strong>: VISSIM, Matlab, ArcGIS, AutoCAD, SpaceGass, RAPT, Revit, Strand7, MS Project, Structural Toolkit, Geo Studio, ANSYS, RESPONSE 2000, MS Office. </li>
<li><strong>Languages</strong>: Chinese (Native), English (Fluent)</li>
</ul>
<!-- --- -->

<!-- ## **Projects**


**E-commerce Platform**  
[GitHub Repository](https://github.com/johndoe/ecommerce-platform)  
*Technologies Used*: React, Node.js, MongoDB, Docker

- Developed a full-stack e-commerce platform with user authentication, product management, and payment integration.
- Implemented a responsive UI using React, improving user interaction on both desktop and mobile devices.
- Deployed the application using Docker containers, ensuring consistent environments across development and production.

**Machine Learning Model for Predictive Analytics**  
[GitHub Repository](https://github.com/johndoe/ml-predictive-analytics)  
*Technologies Used*: Python, Scikit-learn, Pandas, Jupyter Notebook

- Created a machine learning model to predict customer churn, achieving an accuracy of 87%.
- Utilized data preprocessing techniques and feature engineering to improve model performance.
- Documented the project and presented findings in a comprehensive Jupyter Notebook.

--- -->

<!-- ## **Certifications**

- **AWS Certified Solutions Architect** - [Amazon Web Services](https://aws.amazon.com/certification/certified-solutions-architect-associate/), *March 2023*
- **Certified Kubernetes Administrator (CKA)** - [The Linux Foundation](https://www.cncf.io/certification/cka/), *December 2022* -->

<hr>
<h1 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a><strong>Publications</strong></h1><ul>
<li>Zheng, X., Bagloee, S. A., &amp; Sarvi, M. (2024). RecVAE-GBRT: Memory-Fused XGBoost for Time-Series Forecasting. Accepted by <em>International Joint Conference on Neural Networks (IJCNN 2024)</em>.</li>
<li>Zheng, X., Sarvi, M., &amp; Bagloee, S. A. (2023). Interpreting XGBoost for traffic flow forecasting. Accepted by <em>29th ITS World Congress, Suzhou, China</em>.</li>
<li>Zheng, X., Sarvi, M., &amp; Bagloee, S. A. (2022). Deep learning methods for long term traffic flow forecasting. In <em>Australasian Transport Research Forum (ATRF), 43rd, 2022, Adelaide, South Australia, Australia</em>. <strong>Awarded for the best paper.</strong></li>
<li>Zheng, X., Wu, F., Chen, W., Naghizade, E., &amp; Khoshelham, K. (2019). Show me a safer way: Detecting anomalous driving behavior using online traffic footage. Infrastructures, 4(2), 22.</li>
</ul>
<hr>
]]></content>
  </entry>
  <entry>
    <title>End-to-end MLOps with Azure (2)</title>
    <url>/2024/06/07/MLops-with-Azure-2/</url>
    <content><![CDATA[<p><em>I am writing a series of blogs aiming to address arguably the most significant divide between Machine Learning (ML) practitioners in academia and industry: the disparity between development and deployment.</em></p>
<p><strong>This learning note is about how to get an Azure ML job up and running. I organize reliable content and add my input.</strong></p>
<p>You can use Azure Machine Learning jobs to execute any workflow consisting of Python scripts. Azure Machine Learning jobs store all metadata of a workflow, including input parameters and output metrics. </p>
<p>There are different interfaces to use Azure ML, including Azure Machine Learning studio, Python SDK (v2), Azure CLI (v2) and Azure Resource Manager REST APIs. Here we learn how to use Azure CLI (v2) as it works regardless of the programming language used to create the ML scripts.</p>
<p>The new things here are mainly to write YAML files and to run them with Azure CLI. </p>
<p>Specifically, this blog covers three topics: </p>
<ol>
<li>Create Azure Machine Learning resources with the CLI (v2)</li>
<li>Run jobs in Azure Machine Learning with CLI (v2)</li>
<li>Run a hyperparameter tuning job with CLI (v2)</li>
</ol>
<p>For each part, we start with an introduction of some fundamental knowledge, then we move to exercises for hands-on experiences.</p>
<span id="more"></span>

<h1 id="Topic-1-Create-Azure-Machine-Learning-resources-with-the-CLI-v2"><a href="#Topic-1-Create-Azure-Machine-Learning-resources-with-the-CLI-v2" class="headerlink" title="Topic 1: Create Azure Machine Learning resources with the CLI (v2)"></a>Topic 1: Create Azure Machine Learning resources with the CLI (v2)</h1><p>There are two types of compute resources that you most commonly use to train a model:</p>
<ul>
<li>Compute instance: Use tools like <strong>Jupyter and VS Code</strong> with a compute instance to collaborate on notebooks and scripts. You can choose the VM size of the compute instance and start and stop it manually or automatically based on a schedule.</li>
<li>Compute cluster: Can be single or multi-node. Scales up automatically when a job is submitted. More commonly used to run <strong>scheduled jobs and pipelines</strong>.</li>
</ul>
<p>Here we create a compute instance for our task. This can be done with <code>az ml compute create</code>, the parameters needed are:</p>
<ul>
<li>resource-group: Name of resource group. If you configured a default group with az configure ‚Äìdefaults group&#x3D;<name>, you don‚Äôt need to use this parameter.</li>
<li>workspace-name: Name of the Azure Machine Learning workspace. Again if you configured a default workspace with az configure ‚Äìdefaults workspace&#x3D;<name>, you don‚Äôt need to use this parameter.</li>
<li>name: Name of compute target. The name should be fewer than 24 characters and unique within an Azure region. If the name already exists, get a new name and delete the partially created compute instance with az ml compute delete ‚Äìname ‚Äúcompute-instance-name‚Äù.</li>
<li>size: VM size to use for the compute instance.</li>
<li>type: Type of compute target. For example, use <code>ComputeInstance</code> to create a compute instance.</li>
</ul>
<p>A example command:<br><code>az ml compute create --name &quot;testdev-vm&quot; --size STANDARD_DS11_V2 --type ComputeInstance</code></p>
<p>More commands of <code>az ml compute create</code> can be found in <a href="https://learn.microsoft.com/en-us/cli/azure/ml/compute?view=azure-cli-latest">az ml compute</a></p>
<p>Nomally people use compute instance to test the code. After it is running successfully, use compute cluster to training the model so that you can schedule a job to retrain the model whenever it‚Äôs needed. This can be done with some additional settings:</p>
<ul>
<li>type: To create a compute cluster, use <code>AmlCompute</code>.</li>
<li>min-instances: The minimum number of nodes used on the cluster. The default is 0 nodes.</li>
<li>max-instances: The maximum number of nodes. The default is 4.</li>
</ul>
<p>A example command:<br><code>az ml compute create --name &quot;aml-cluster&quot; --size STANDARD_DS11_V2 --max-instances 2 --type AmlCompute</code></p>
<p>To train the model on either a compute instance or compute cluster, all necessary packages need to be installed on the compute to run the code. Instead of manually installing these packages every time you use a new compute, you can list them in an environment.Every Azure Machine Learning workspace will by default have a list of curated environments when you create the workspace. Curated environments include common machine learning packages to train a model.</p>
<p>If you need to create your own environment because none of the curated environments meet your needs, create a YAML:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/environment.schema.json</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">basic-env-scikit</span></span><br><span class="line"><span class="attr">version:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">image:</span> <span class="string">mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04</span></span><br><span class="line"><span class="attr">conda_file:</span> <span class="string">file:conda-envs/basic-env-ml.yml</span></span><br></pre></td></tr></table></figure>
<p>in which the conda_file (Conda environment file) can be:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">basic-env-ml</span></span><br><span class="line"><span class="attr">channels:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">conda-forge</span></span><br><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">python=3.8</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pip</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pip:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">numpy</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">pandas</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">scikit-learn</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">matplotlib</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">azureml-mlflow</span></span><br></pre></td></tr></table></figure>

<p>With these YAML files ready, run:<br><code>az ml environment create --file basic-env.yml</code></p>
<p>Use <code>az ml environment list</code> to list all the datasets in the workspace.</p>
<p>You could upload the CSV dataset to the compute instance, but to train the model with a compute cluster afterwards, you should create a dataset asset from a local file. To do this, first create a YAML file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/asset.schema.json</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">customer-churn-data</span></span><br><span class="line"><span class="attr">version:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">local_path:</span> <span class="string">customer-churn.csv</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Dataset</span> <span class="string">pointing</span> <span class="string">to</span> <span class="string">customer</span> <span class="string">churn</span> <span class="string">CSV</span> <span class="string">on</span> <span class="string">local</span> <span class="string">computer.</span> <span class="string">Data</span> <span class="string">will</span> <span class="string">be</span> <span class="string">uploaded</span> <span class="string">to</span> <span class="string">default</span> <span class="string">datastore.</span></span><br></pre></td></tr></table></figure>
<p>Then use:</p>
<p><code>az ml dataset create --file data-local-path.yml</code></p>
<p>Use <code>az ml dataset list</code> to list all the datasets in the workspace.</p>
<p>To track machine learning workloads in Azure Machine Learning, use jobs to train models. </p>
<p>With the basic ideas in mind, let‚Äôs try for the following exercises:</p>
<h2 id="Topic-1-Exercise-Create-an-Azure-Machine-Learning-workspace-and-assets-with-the-CLI-v2"><a href="#Topic-1-Exercise-Create-an-Azure-Machine-Learning-workspace-and-assets-with-the-CLI-v2" class="headerlink" title="Topic 1 Exercise: Create an Azure Machine Learning workspace and assets with the CLI (v2)"></a>Topic 1 Exercise: <a href="https://microsoftlearning.github.io/mslearn-aml-cli/Instructions/Labs/01-create-workspace.html">Create an Azure Machine Learning workspace and assets with the CLI (v2)</a></h2><p>This exercise provides a step-by-step example so I no more record many details. The key steps include:</p>
<ol>
<li>Set up the Azure Cloud Shell and install the Azure Machine Learning extension.</li>
</ol>
<ul>
<li>Check to see if the Azure Machine Learning extension is installed with <code> az extension list</code>. Adding -o table at the end of the command will format the output in a table, making it easier to read for some people. The command would then be: az extension list -o table.</li>
<li>Clone the desired Github repository like <code>git clone https://github.com/MicrosoftLearning/mslearn-aml-cli.git mslearn-aml-cli</code>. Then <code>ls</code> you can see the <code>mslearn-aml-cli</code> folder.</li>
</ul>
<ol start="2">
<li>Create an Azure resource group and set as default</li>
<li>Create an Azure Machine Learning workspace and set as default. With the provided code, the following error occurs:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Code: ValidationError</span><br><span class="line">Message: Missing dependent resources <span class="keyword">in</span> workspace json</span><br><span class="line">Target: workspace</span><br><span class="line">Exception Details:      (Invalid) Missing dependent resources <span class="keyword">in</span> workspace json</span><br><span class="line">        Code: Invalid</span><br><span class="line">        Message: Missing dependent resources <span class="keyword">in</span> workspace json</span><br><span class="line">        Target: workspace</span><br></pre></td></tr></table></figure>

<p>Upon test, this is a a general issue with the extension ml in version 2.26.0. It can be resolved by running these commands in a local bash (must be a local bash cause Cloud Shell in Azure does not allow modifying the version of ml) (<a href="https://stackoverflow.com/questions/78550892/unable-to-create-an-azure-machine-learning-workspace-using-the-cli">https://stackoverflow.com/questions/78550892/unable-to-create-an-azure-machine-learning-workspace-using-the-cli</a>):</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">az extension remove -n azure-cli-ml</span><br><span class="line">az extension remove -n ml</span><br><span class="line">az extension add -n ml --version=2.25.0</span><br></pre></td></tr></table></figure>
<p>However we cannot do this with Azure Cloud Shell we are using (to change version of ml we have to wait for its next update). Therefore I continued with local bash.</p>
<ol start="4">
<li><p>Create a Compute Instance. The command will take 2 to 5 minutes to complete. You can click Azure Machine Learning Studio and find the workspace-&gt;compute to check if an instance is running.</p>
</li>
<li><p>Create an environment. This is to automate the installation of the necessary libraries and packages for running the Python script.You can click Azure Machine Learning Studio and find the workspace-&gt;environment to check. </p>
</li>
<li><p>Create a dataset. </p>
</li>
<li><p>Clean up resources. Stop the compute instance once finished to avoid unnecessary charges. You will however be charged a small amount for data storage as long as the Azure Machine Learning workspace exists in your subscription. If you have finished exploring Azure Machine Learning, you can delete the Azure Machine Learning workspace and associated resources. However, if you plan to complete any other labs in this series, you will need to repeat this lab to create the workspace and prepare the environment first.</p>
</li>
</ol>
<h1 id="Topic-2-Run-jobs-in-Azure-Machine-Learning-with-CLI-v2"><a href="#Topic-2-Run-jobs-in-Azure-Machine-Learning-with-CLI-v2" class="headerlink" title="Topic 2: Run jobs in Azure Machine Learning with CLI (v2)"></a>Topic 2: Run jobs in Azure Machine Learning with CLI (v2)</h1><p>To track machine learning workloads in Azure Machine Learning, use <code>jobs</code> to train models.<br>The inputs of a model are listed in the YAML file needed to submit a job. In that YAML file, you‚Äôll include the basics:</p>
<ul>
<li>What to run: The training script.</li>
<li>How to run it: The environment needed to run the code.</li>
<li>Where to run it: The compute used to execute the code.</li>
</ul>
<p>A example YAML file is:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/commandJob.schema.json</span></span><br><span class="line"><span class="attr">code:</span> </span><br><span class="line">  <span class="attr">local_path:</span> <span class="string">src</span></span><br><span class="line"><span class="attr">command:</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">  python main.py </span></span><br><span class="line"><span class="string"></span><span class="attr">environment:</span> <span class="string">azureml:basic-env-scikit:1</span></span><br><span class="line"><span class="attr">compute:</span> <span class="string">azureml:testdev-vm</span></span><br><span class="line"><span class="attr">experiment_name:</span> <span class="string">customer-churn</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Train</span> <span class="string">a</span> <span class="string">classification</span> <span class="string">model</span> <span class="string">on</span> <span class="string">a</span> <span class="string">sample</span> <span class="string">customer</span> <span class="string">dataset.</span></span><br></pre></td></tr></table></figure>
<p>In which:</p>
<ul>
<li>the prefix <code>azureml</code> refers to an asset within your Azure Machine Learning workspace</li>
<li>code.local_path: The local path to the training script.</li>
<li>command: The command to execute, which is to run the script with Python.</li>
<li>environment: The environment needed to execute the command. You can refer to a registered environment from the workspace by using the prefix azureml:, or define an environment inline.</li>
<li>compute: The compute target on which the code will run. You can use local compute, or the compute instance or cluster from the workspace.</li>
<li>experiment_name: The job will be stored as an experiment run in the workspace. Optionally, you can add the experiment name to more easily find it in the Studio. By default, a name will be created for you.</li>
<li>description: Optionally, add a description to give more information on what the job included.</li>
</ul>
<p>Submit YAML file with:<br><code>az ml job create --file job.yml --web</code></p>
<p>When you include the parameter ‚Äìweb, a web page will open after the job is submitted so you can monitor the experiment run in the Azure Machine Learning Studio.</p>
<p>To train multiple models with varying inputs but the same training script, data scientists can work with input arguments. <strong>To easily change the input dataset every time you want to retrain the model, you want to create an input argument for the data</strong>. This needs two things:</p>
<ul>
<li>In the script: You define the input arguments using the argparse module. You specify the argument‚Äôs name, type and optionally a default value.</li>
<li>In the YAML file: You specify the data input, which will mount (default option) or download data to the local file system. You can refer to a public URI or a registered dataset in the Azure Machine Learning workspace.</li>
</ul>
<p>The YAML file can be:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/commandJob.schema.json</span></span><br><span class="line"><span class="attr">code:</span> </span><br><span class="line">  <span class="attr">local_path:</span> <span class="string">src</span></span><br><span class="line"><span class="attr">command:</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">  python main.py</span></span><br><span class="line"><span class="string">  --data-csv $&#123;&#123;inputs.dataset&#125;&#125;</span></span><br><span class="line"><span class="string"></span><span class="attr">inputs:</span></span><br><span class="line">  <span class="attr">dataset:</span> <span class="string">azureml:customer-churn-data:1</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">download</span> </span><br><span class="line"><span class="attr">environment:</span> <span class="string">azureml:basic-env-scikit:1</span></span><br><span class="line"><span class="attr">compute:</span> <span class="string">azureml:testdev-vm</span></span><br><span class="line"><span class="attr">experiment_name:</span> <span class="string">customer-churn</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Train</span> <span class="string">a</span> <span class="string">classification</span> <span class="string">model</span> <span class="string">on</span> <span class="string">a</span> <span class="string">sample</span> <span class="string">customer</span> <span class="string">dataset.</span></span><br></pre></td></tr></table></figure>

<p>It will take version 1 of the customer-churn-data dataset from your Azure Machine Learning workspace, download it to the file system of the compute instance testdev-vm, and then run the main.py script with the dataset as an input argument.</p>
<h2 id="Topic-2-Exercise-Run-a-basic-Python-training-job"><a href="#Topic-2-Exercise-Run-a-basic-Python-training-job" class="headerlink" title="Topic 2 Exercise: Run a basic Python training job"></a>Topic 2 Exercise: <a href="https://microsoftlearning.github.io/mslearn-aml-cli/Instructions/Labs/02-run-python-job.html">Run a basic Python training job</a></h2><p>In the previous exercise we created a compute instance with name: ‚Äútestdev-vm‚Äù. </p>
<p>In the end we stopped the compute instance. Now start the instance again by using the following command:</p>
<p><code>az ml compute start --name &quot;testdev-vm&quot;</code></p>
<p>Get the following YAML file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/commandJob.schema.json</span></span><br><span class="line"><span class="attr">code:</span> <span class="string">src</span></span><br><span class="line"><span class="attr">command:</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">  python main.py </span></span><br><span class="line"><span class="string"></span><span class="attr">environment:</span> <span class="string">azureml:basic-env-scikit@latest</span></span><br><span class="line"><span class="attr">compute:</span> <span class="string">azureml:testdev-vm</span></span><br><span class="line"><span class="attr">experiment_name:</span> <span class="string">diabetes-example</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Train</span> <span class="string">a</span> <span class="string">Logistic</span> <span class="string">Regression</span> <span class="string">classification</span> <span class="string">model</span> <span class="string">on</span> <span class="string">the</span> <span class="string">diabetes</span> <span class="string">dataset</span> <span class="string">that</span> <span class="string">is</span> <span class="string">stored</span> <span class="string">locally.</span></span><br></pre></td></tr></table></figure>

<p>You can see that no input is given, this is because the main.py said to directly read the csv file in the same folder.</p>
<p>With the code and YAML file ready, run:<br><code>az ml job create --file ./mslearn-aml-cli/Allfiles/Labs/02/basic-job/basic-job.yml</code></p>
<p>Return to your Azure Machine Learning Studio browser tab, go to the Jobs page and locate the diabetes-example experiment in the All experiments tab.</p>
<p>Open the run to monitor the job and refresh the view if necessary. Once completed, you can explore the details of the job which are stored in the experiment run.</p>
<p>You can also train a model using a registered dataset as input with the following YAML:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/commandJob.schema.json</span></span><br><span class="line"><span class="attr">code:</span> <span class="string">src</span></span><br><span class="line"><span class="attr">command:</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">  python main.py </span></span><br><span class="line"><span class="string">  --diabetes-csv $&#123;&#123;inputs.diabetes&#125;&#125;</span></span><br><span class="line"><span class="string"></span><span class="attr">inputs:</span></span><br><span class="line">  <span class="attr">diabetes:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">azureml:diabetes-data:1</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="string">ro_mount</span></span><br><span class="line"><span class="attr">environment:</span> <span class="string">azureml:basic-env-scikit@latest</span></span><br><span class="line"><span class="attr">compute:</span> <span class="string">azureml:&lt;your-compute-instance-name&gt;</span></span><br><span class="line"><span class="attr">experiment_name:</span> <span class="string">diabetes-data-example</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Train</span> <span class="string">a</span> <span class="string">classification</span> <span class="string">model</span> <span class="string">on</span> <span class="string">diabetes</span> <span class="string">data</span> <span class="string">using</span> <span class="string">a</span> <span class="string">registered</span> <span class="string">dataset</span> <span class="string">as</span> <span class="string">input.</span></span><br></pre></td></tr></table></figure>
<p>After the jobs are done, clean up resources. Stop a compute instance:</p>
<p><code>az ml compute stop --name &quot;testdev-vm&quot; --no-wait</code></p>
<h1 id="Topic-3-Run-a-hyperparameter-tuning-job-with-CLI-v2-‚Äô"><a href="#Topic-3-Run-a-hyperparameter-tuning-job-with-CLI-v2-‚Äô" class="headerlink" title="Topic 3: Run a hyperparameter tuning job with CLI (v2)‚Äô"></a>Topic 3: Run a hyperparameter tuning job with CLI (v2)‚Äô</h1><p>With a compute cluster, you can parallelize the model training to quickly iterate through hyperparameter values. A example YAML file looks like:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/sweepJob.schema.json</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">sweep</span> </span><br><span class="line"><span class="attr">sampling_algorithm:</span> <span class="string">grid</span> </span><br><span class="line"><span class="attr">trial:</span></span><br><span class="line">  <span class="attr">code:</span> </span><br><span class="line">    <span class="attr">local_path:</span> <span class="string">src</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">    python main.py</span></span><br><span class="line"><span class="string">    --learning-rate $&#123;&#123;search_space.learning_rate&#125;&#125;</span></span><br><span class="line"><span class="string"></span>  <span class="attr">environment:</span> <span class="string">azureml:basic-env-scikit:1</span></span><br><span class="line"><span class="attr">inputs:</span></span><br><span class="line">    <span class="attr">diabetes:</span></span><br><span class="line">      <span class="attr">data:</span> <span class="string">azureml:diabetes-data:1</span></span><br><span class="line"><span class="attr">compute:</span> <span class="string">azureml:aml-cluster</span></span><br><span class="line"><span class="attr">search_space:</span></span><br><span class="line">  <span class="attr">learning_rate:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">choice</span></span><br><span class="line">    <span class="attr">values:</span> [<span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="attr">objective:</span></span><br><span class="line">  <span class="attr">primary_metric:</span> <span class="string">training_roc_auc_score</span></span><br><span class="line">  <span class="attr">goal:</span> <span class="string">maximize</span></span><br><span class="line"><span class="attr">limits:</span></span><br><span class="line">  <span class="attr">max_total_trials:</span> <span class="number">6</span></span><br><span class="line">  <span class="attr">max_concurrent_trials:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">timeout:</span> <span class="number">3600</span></span><br><span class="line"><span class="attr">experiment_name:</span> <span class="string">customer-churn-sweep-example</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Run</span> <span class="string">a</span> <span class="string">hyperparameter</span> <span class="string">sweep</span> <span class="string">job</span> <span class="string">for</span> <span class="string">classification</span> <span class="string">on</span> <span class="string">customer</span> <span class="string">churn</span> <span class="string">dataset.</span></span><br></pre></td></tr></table></figure>
<p>In which:</p>
<ul>
<li>type: The job type, which in this case is sweep_job.</li>
<li>algorithm: The sampling method used to choose values from the search space. Can be bayesian, grid, or random.</li>
<li>search_space: The set of values tried during hyperparameter tuning. For each hyperparameter, you can configure the search space type (choice) and values (0.01, 0.1, 1.0).</li>
<li>objective: The name of the logged metric that is used to decide which model is best (primary_metric). And whether that metric is best when maximized or minimized (goal).</li>
<li>max_total_trials: A hard stop for how many models to train in total.</li>
<li>max_concurrent_trials: When you use a compute cluster, you can train models in parallel. The number of maximum concurrent trials can‚Äôt be higher than the number of nodes provisioned for the compute cluster.</li>
</ul>
<h2 id="Topic-3-Exercise-Run-a-sweep-job-to-tune-hyperparameters"><a href="#Topic-3-Exercise-Run-a-sweep-job-to-tune-hyperparameters" class="headerlink" title="Topic 3 Exercise: Run a sweep job to tune hyperparameters"></a>Topic 3 Exercise: <a href="https://microsoftlearning.github.io/mslearn-aml-cli/Instructions/Labs/03-run-sweep-job.html">Run a sweep job to tune hyperparameters</a></h2><p>Use a sweep job to train multiple models with varying hyperparameters.</p>
<p>Here yo train multiple models in parallel, we use compute cluster:</p>
<p><code> az ml compute create --name &quot;aml-cluster&quot; --size STANDARD_DS11_V2 --max-instances 2 --type AmlCompute</code></p>
<p>Creating a compute cluster with two maximum instances means you can train two models in parallel. </p>
<p>Check Compute tab, then select Compute clusters to verify if it is created successfully.</p>
<p>The YAML file looks like:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/sweepJob.schema.json</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">sweep</span></span><br><span class="line"><span class="attr">sampling_algorithm:</span> <span class="string">grid</span></span><br><span class="line"><span class="attr">trial:</span></span><br><span class="line">  <span class="attr">code:</span> <span class="string">src</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">    python main.py</span></span><br><span class="line"><span class="string">    --diabetes-csv $&#123;&#123;inputs.diabetes&#125;&#125; </span></span><br><span class="line"><span class="string">    --learning-rate $&#123;&#123;search_space.learning_rate&#125;&#125;</span></span><br><span class="line"><span class="string">    --n-estimators $&#123;&#123;search_space.n_estimators&#125;&#125;</span></span><br><span class="line"><span class="string"></span>  <span class="attr">environment:</span> <span class="string">azureml:basic-env-scikit@latest</span></span><br><span class="line"><span class="attr">inputs:</span></span><br><span class="line">  <span class="attr">diabetes:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">azureml:diabetes-data:1</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="string">ro_mount</span></span><br><span class="line"><span class="attr">compute:</span> <span class="string">azureml:aml-cluster</span></span><br><span class="line"><span class="attr">search_space:</span></span><br><span class="line">  <span class="attr">learning_rate:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">choice</span></span><br><span class="line">    <span class="attr">values:</span> [<span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.0</span>]</span><br><span class="line">  <span class="attr">n_estimators:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">choice</span></span><br><span class="line">    <span class="attr">values:</span> [<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="attr">objective:</span></span><br><span class="line">  <span class="attr">primary_metric:</span> <span class="string">training_roc_auc_score</span></span><br><span class="line">  <span class="attr">goal:</span> <span class="string">maximize</span></span><br><span class="line"><span class="attr">limits:</span></span><br><span class="line">  <span class="attr">max_total_trials:</span> <span class="number">6</span></span><br><span class="line">  <span class="attr">max_concurrent_trials:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">timeout:</span> <span class="number">3600</span></span><br><span class="line"><span class="attr">experiment_name:</span> <span class="string">diabetes-sweep-example</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Run</span> <span class="string">a</span> <span class="string">hyperparameter</span> <span class="string">sweep</span> <span class="string">job</span> <span class="string">for</span> <span class="string">classification</span> <span class="string">on</span> <span class="string">diabetes</span> <span class="string">dataset.</span></span><br></pre></td></tr></table></figure>

<p>Basically giving ‚Äúlearning-rate‚Äù and ‚Äún-estimators‚Äù in the Python script search spaces.</p>
<p>With the code and YAML file ready, run:<br><code> az ml job create --file ./mslearn-aml-cli/Allfiles/Labs/02/sweep-job/sweep-job.yml</code></p>
<p>The compute cluster will automatically scale down to 0 nodes, so <em><strong>there is no need to stop the cluster</strong></em>.</p>
<hr>
<p>References:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-v2?view=azureml-api-2">What is Azure Machine Learning CLI and Python SDK v2</a></li>
<li><a href="https://learn.microsoft.com/en-us/training/paths/train-models-azure-machine-learning-cli-v2/">Train models in Azure Machine Learning with the CLI (v2)</a></li>
</ul>
<hr>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>MLops</tag>
        <tag>Azure</tag>
      </tags>
  </entry>
  <entry>
    <title>Install and set up the Azure CLI (v2)</title>
    <url>/2024/06/04/Install-and-set-up-the-CLI-v2/</url>
    <content><![CDATA[<h1 id="Install-the-Azure-CLI-and-its-Machine-Learning-extension"><a href="#Install-the-Azure-CLI-and-its-Machine-Learning-extension" class="headerlink" title="Install the Azure CLI and its Machine Learning extension"></a>Install the Azure CLI and its Machine Learning extension</h1><p>The Azure Command-Line Interface (CLI) is a cross-platform command-line tool to connect to Azure and execute administrative commands on Azure resources. It allows the execution of commands through a terminal using interactive command-line prompts or a script.</p>
<p>For interactive use, first launch a shell such as cmd.exe on Windows, or Bash on Linux or macOS, and then issue a command at the shell prompt. To automate repetitive tasks, assemble the CLI commands into a shell script using the script syntax of your chosen shell, and then you execute the script.</p>
<p>Here we install the Azure CLI locally using PowerShell. To do this, start PowerShell as administrator and run the following command:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ProgressPreference</span> = <span class="string">&#x27;SilentlyContinue&#x27;</span>; <span class="built_in">Invoke-WebRequest</span> <span class="literal">-Uri</span> https://aka.ms/installazurecliwindowsx64 <span class="literal">-OutFile</span> .\AzureCLI.msi; <span class="built_in">Start-Process</span> msiexec.exe <span class="literal">-Wait</span> <span class="literal">-ArgumentList</span> <span class="string">&#x27;/I AzureCLI.msi /quiet&#x27;</span>; <span class="built_in">Remove-Item</span> .\AzureCLI.msi</span><br></pre></td></tr></table></figure>
<p>The powershell will not show anything. Reopen the console, type in ‚Äúaz‚Äù to make sure the installation is successful.</p>
<span id="more"></span>
<p>Remove any existing installation of the ml extension and also the CLI v1 azure-cli-ml extension:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">az extension remove <span class="literal">-n</span> azure<span class="literal">-cli-ml</span></span><br><span class="line">az extension remove <span class="literal">-n</span> ml</span><br></pre></td></tr></table></figure>

<p>Now, install the ml extension:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">az extension add <span class="literal">-n</span> ml</span><br></pre></td></tr></table></figure>
<p>You can use the help command with:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">az ml <span class="literal">-h</span></span><br></pre></td></tr></table></figure>

<p>And upgrade the extension with:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">az extension update <span class="literal">-n</span> ml</span><br></pre></td></tr></table></figure>

<h1 id="Log-in-and-Set-up"><a href="#Log-in-and-Set-up" class="headerlink" title="Log in and Set up"></a>Log in and Set up</h1><p>To log inÔºö</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">az login</span><br></pre></td></tr></table></figure>
<p>Setup common variables (change as required):</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$GROUP</span>=<span class="string">&quot;azureml-examples&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$LOCATION</span>=<span class="string">&quot;eastus&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$WORKSPACE</span>=<span class="string">&quot;main&quot;</span></span><br></pre></td></tr></table></figure>

<p>Then create the Azure resource group:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">az <span class="built_in">group</span> create <span class="literal">-n</span> <span class="variable">$GROUP</span> <span class="literal">-l</span> <span class="variable">$LOCATION</span></span><br></pre></td></tr></table></figure>
<p>Then create a machine learning workspace:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">az ml workspace create <span class="literal">-n</span> <span class="variable">$WORKSPACE</span> <span class="literal">-g</span> <span class="variable">$GROUP</span> <span class="literal">-l</span> <span class="variable">$LOCATION</span></span><br></pre></td></tr></table></figure>

<p>Set the default resource group and default workspace so that you don‚Äôt have to include them as parameters each time you want to run a command.</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">az configure <span class="literal">--defaults</span> <span class="built_in">group</span>=<span class="string">&quot;azureml-examples&quot;</span></span><br><span class="line">az configure <span class="literal">--defaults</span> workspace=<span class="string">&quot;main&quot;</span></span><br></pre></td></tr></table></figure>








<hr>
<p>References:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/cli/azure/install-azure-cli">How to install the Azure CLI</a></li>
<li><a href="https://learn.microsoft.com/en-gb/azure/machine-learning/how-to-configure-cli?view=azureml-api-2&tabs=public">Install and set up the CLI (v2)</a></li>
</ul>
<hr>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>MLops</tag>
        <tag>Azure</tag>
      </tags>
  </entry>
  <entry>
    <title>End-to-end MLOps with Azure (1)</title>
    <url>/2024/06/03/MLops-with-Azure/</url>
    <content><![CDATA[<p><em>I am writing a series of blogs aiming to address arguably the most significant divide between Machine Learning (ML) practitioners in academia and industry: the disparity between development and deployment.</em></p>
<p><strong>This learning note is about some basic concepts in MLOps, and the very first step to get an Azure ML job up and running. I organize reliable content (from the references at the end) and add my input.</strong></p>
<p>Typically, researchers, even those focused on applications, conclude their workflow once the model is evaluated (and hopefully generated strong performance). However, to apply the developed model to real-world problems, the critical missing step is to ‚Äúoperationalize‚Äù the model.</p>
<p>The key steps to operationalize a ML model:</p>
<ul>
<li>Convert the model training into a robust and reproducible pipeline.</li>
<li>Test the code and the model in a development environment.</li>
<li>Deploy the model in a production environment.</li>
<li>Automate the end-to-end process.</li>
</ul>
<span id="more"></span>

<h1 id="The-Overall-architecture"><a href="#The-Overall-architecture" class="headerlink" title="The Overall architecture"></a>The Overall architecture</h1><p>The overall architecture of developing and deployment a ML model with Azure contains 4 steps:</p>
<ol>
<li>All data will be stored in an <em>Azure Blob Storage</em>, which will be managed by the data engineer.</li>
<li>The infrastructure team will create necessary Azure resources like the <em>Azure Machine Learning workspace</em>.</li>
<li>The data scientist will focus on the inner loop: developing and training the model.</li>
<li>The machine learning engineer will take the trained model and deploy it in the outer loop.</li>
</ol>
<p><strong>The main goal: create a robust and reproducible solution with the output from data scientists.</strong></p>
<h1 id="The-key-YAML-file-to-create-Azure-Machine-Learning-jobs"><a href="#The-key-YAML-file-to-create-Azure-Machine-Learning-jobs" class="headerlink" title="The key YAML file to create Azure Machine Learning jobs"></a>The key YAML file to create Azure Machine Learning jobs</h1><p><em><strong>Assume you have this</strong></em>: a Jupyter notebook in which data is loaded, transformed, and trained.</p>
<p>To define a job in Azure Machine Learning, you can use Azure Machine Learning CLI v2 interface, which creates a YAML file to define the configuration of the asset or workflow. The YAML file details:</p>
<ul>
<li>Which scripts to run.</li>
<li>What the inputs and outputs are for each script.</li>
<li>The compute that will be used to run the scripts.</li>
<li>The environment that needs to be installed on the compute to run the scripts.</li>
</ul>
<p>and can be used to run one script as a command job or multiple scripts sequentially as a pipeline.</p>
<p>A example YAML code:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/latest/commandJob.schema.json</span></span><br><span class="line"><span class="attr">code:</span> <span class="string">src</span> <span class="comment"># refers to the local folder, which stores the scripts</span></span><br><span class="line"><span class="attr">command:</span> <span class="string">&gt;-  </span></span><br><span class="line"><span class="string">  python main.py </span></span><br><span class="line"><span class="string">  --diabetes-csv $&#123;&#123;inputs.diabetes&#125;&#125; </span></span><br><span class="line"><span class="string"></span><span class="attr">inputs:</span></span><br><span class="line">  <span class="attr">diabetes:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">azureml:diabetes-data:1</span> <span class="comment"># Version 1 of the registered data asset diabetes-data</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="string">ro_mount</span></span><br><span class="line"><span class="attr">environment:</span> <span class="string">azureml:basic-env-scikit@latest</span></span><br><span class="line"><span class="attr">compute:</span> <span class="string">azureml:aml-instance</span> <span class="comment"># The compute instance aml-instance will be used to run the scripts.</span></span><br><span class="line"><span class="attr">experiment_name:</span> <span class="string">diabetes-data-example</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Train</span> <span class="string">a</span> <span class="string">classification</span> <span class="string">model</span> <span class="string">on</span> <span class="string">diabetes</span> <span class="string">data</span> <span class="string">using</span> <span class="string">a</span> <span class="string">registered</span> <span class="string">dataset</span> <span class="string">as</span> <span class="string">input.</span></span><br></pre></td></tr></table></figure>

<p>The <code>command</code> specifies that the main.py script in the src folder should be executed, using the value of inputs.diabetes for the diabetes-csv parameter.</p>
<p>The latest version of the registered custom basic-env-scikit environment will be installed on the compute instance before running the script.</p>
<p>CLI v2 can be used to run an Azure ML job. It can be installed on the local device or be used with Azure Cloud Shell. In both ways you need to install the Azure ML extension. Installing on windows can be done by:</p>
<p><code>az extension add -n ml -y</code></p>
<p>Then, with the access to the Azure subscription ready, you can submit the job with:</p>
<p><code>az ml job create --file job.yml</code></p>
<p>For YAML commands, see <a href="https://learn.microsoft.com/en-gb/azure/machine-learning/reference-yaml-job-command?view=azureml-api-2">YAML commands for AzureML</a>. </p>
<h1 id="The-first-step-Convert-a-notebook-to-production-code"><a href="#The-first-step-Convert-a-notebook-to-production-code" class="headerlink" title="The first step: Convert a notebook to production code"></a>The first step: Convert a notebook to production code</h1><p>The first step is to Convert a Jupyter notebook to production-ready code (Python scripts). Most of this part is standard stuff: remove nonessential code, organize them in functions, etc. The new thing here is to track and manage ML models. We can use autologging since the model in this challenge is trained with the common Scikit-learn library.The whole process can be as simple as:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> mlflow</span><br><span class="line">mlflow.autolog() <span class="comment"># put this in the main function</span></span><br></pre></td></tr></table></figure>


<p>In the next blog, we will learn to dig deeper into training models in Azure Machine Learning with the CLI (v2).</p>
<hr>
<p>References:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/training/paths/build-first-machine-operations-workflow/">End-to-end machine learning operations (MLOps) with Azure Machine Learning</a></li>
</ul>
<hr>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>MLops</tag>
        <tag>Azure</tag>
      </tags>
  </entry>
  <entry>
    <title>Pick the right Azure service and compute resource</title>
    <url>/2024/06/02/Pick-the-right-Azure-service-and-compute-resource/</url>
    <content><![CDATA[<h1 id="Pick-the-right-Azure-service-to-train-your-model"><a href="#Pick-the-right-Azure-service-to-train-your-model" class="headerlink" title="Pick the right Azure service to train your model"></a>Pick the right Azure service to train your model</h1><p>Picking the right Azure service for model training is a essential step, which depends on factors including:</p>
<ul>
<li>What type of model you need to train.</li>
<li>Whether you need full control over model training.</li>
<li>How much time you want to invest in model training.</li>
<li>Which services are already within your organization.</li>
<li>Which programming language you‚Äôre comfortable with.</li>
</ul>
<p>Commonly used Azure services for model training are introduced as follows:</p>
<span id="more"></span>

<ul>
<li><p><strong>Azure Machine Learning</strong> gives you many different options (including Jupyter notebooks) to train and manage your machine learning models. You can choose to work with the Studio for a UI-based experience, or manage your machine learning workloads with the Python SDK, or CLI for a code-first experience.</p>
</li>
<li><p><strong>Azure Databricks</strong> is a data analytics platform that you can use for data engineering and data science. Azure Databricks uses <strong>distributed Spark compute</strong> to efficiently process your data. You can choose to train and manage models with Azure Databricks or by integrating Azure Databricks with other services such as Azure Machine Learning.</p>
</li>
<li><p><strong>Azure Synapse Analytics</strong> is an analytics service, which uses distributed compute for big data analytics. Azure Synapse Analytics is <strong>primarily designed to ingest and transform data at scale but also includes several machine learning capabilities</strong>. To train models with Azure Synapse Analytics, you can train models on Spark pools with MLlib or use the integrated Automated Machine Learning feature from Azure Machine Learning.</p>
</li>
<li><p><strong>Azure AI Services</strong> is a collection of <strong>prebuilt machine learning models</strong> you can use for common machine learning tasks such as object detection in images. The models are offered as an application programming interface (API), so you can easily integrate a model with your application. Some models can be customized with your own training data, saving time and resources to train a new model from scratch.</p>
</li>
</ul>
<p>Here is a general guidance provided by Microsoft:</p>
<ul>
<li>Use Azure AI Services whenever one of the customizable prebuilt models suits your requirements, to save time and effort.</li>
<li>Use Azure Synapse Analytics or Azure Databricks if you want to keep all data-related (data engineering and data science) projects within the same service.</li>
<li>Use Azure Synapse Analytics or Azure Databricks if you need <strong>distributed compute for working with large datasets (datasets are large when you experience capacity constraints with standard compute)</strong>. You‚Äôll need to work with PySpark to use the distributed compute.</li>
<li>Use Azure Machine Learning or Azure Databricks when you want full control over model training and management.</li>
<li>Use Azure Machine Learning when Python is your preferred programming language.</li>
<li>Use Azure Machine Learning when you want an intuitive user interface to manage your machine learning lifecycle.</li>
</ul>
<h1 id="Decide-between-compute-options"><a href="#Decide-between-compute-options" class="headerlink" title="Decide between compute options"></a>Decide between compute options</h1><h2 id="The-type-of-virtual-machine"><a href="#The-type-of-virtual-machine" class="headerlink" title="The type of virtual machine"></a>The type of virtual machine</h2><ul>
<li>General purpose: Have a balanced CPU-to-memory ratio. Ideal for testing and development with smaller datasets.</li>
<li>Memory optimized: Have a high memory-to-CPU ratio (better performance when loading and exploring data directly in the notebook). Great for in-memory analytics, which is ideal when you have larger datasets or when you‚Äôre working in notebooks.</li>
</ul>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><p>Spark is available for Azure Synapse Analytics and Azure Databricks. It works like this:</p>
<p>A Spark cluster consists of a driver node and worker nodes. Your code will initially communicate with the driver node. The work is then distributed across the worker nodes. When you use a service that distributes the work, parts of the workload can be executed in parallel, reducing the processing time. Finally, the work is summarized and the driver node communicates the result back to you.</p>
<p><strong>You cannot run a python script to use Spark</strong>. It will only use the driver node and not use the worker nodes. To use Spark, the code needs to be written in a Spark-friendly language like Scala, SQL, RSpark, or PySpark in order to distribute the workload.</p>
<h2 id="Monitoring-the-compute-utilization"><a href="#Monitoring-the-compute-utilization" class="headerlink" title="Monitoring the compute utilization"></a>Monitoring the compute utilization</h2><p>Monitor how long the model training takes and how much compute is used to know whether to scale the compute up or down. </p>
<hr>
<p>References:</p>
<ul>
<li><p><a href="https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/3-choose-service-train">Choose a service to train a machine learning model</a></p>
</li>
<li><p><a href="https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/4-decide-between-compute-options">Decide between compute options</a></p>
</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>MLops</tag>
        <tag>Azure</tag>
      </tags>
  </entry>
  <entry>
    <title>Serve Data to Machine Learning Workflows with Azure</title>
    <url>/2024/06/01/Data-ingestion-Azure/</url>
    <content><![CDATA[<h1 id="Common-options-for-storing-data"><a href="#Common-options-for-storing-data" class="headerlink" title="Common options for storing data"></a>Common options for storing data</h1><p>When you use Azure Machine Learning, Azure Databricks, or Azure Synapse Analytics for model training, there are three options for storing data:</p>
<ul>
<li>Azure Blob Storage: <strong>Cheapest option</strong> for storing data as unstructured data. Ideal for storing files like images, text, and JSON. Often also used to store data as CSV files, as data scientists prefer working with CSV files.</li>
<li>Azure Data Lake Storage (Gen 2): A more advanced version of the Azure Blob Storage. Also stores files like CSV files and images as unstructured data. A data lake also implements a hierarchical namespace, which means it‚Äôs easier to give someone access to a specific file or folder, in other words, <strong>more granular control over who has access to what</strong>. Storage capacity is virtually <strong>limitless</strong> so <strong>ideal for storing large data</strong>. </li>
<li>Azure SQL Database: Stores data as <strong>structured data</strong>. Data is read as a table and schema is defined when a table in the database is created. Ideal for data that doesn‚Äôt change over time.</li>
</ul>
<span id="more"></span>

<h1 id="Common-options-for-data-ingestion-solution"><a href="#Common-options-for-data-ingestion-solution" class="headerlink" title="Common options for data ingestion solution"></a>Common options for data ingestion solution</h1><p>Data ingestion pipeline is used to move and transform data. You can use one of the following services (these services can be used to train the machine learning model):</p>
<ul>
<li><p>Azure Synapse Analytics&#x2F;Azure Synapse Pipelines:</p>
<ol>
<li>Create and schedule data ingestion pipelines through the easy-to-use UI, or by defining the pipeline in JSON format. </li>
<li>Easily copy data from one source to a data store.</li>
<li>Allows you to choose between different types of compute that can handle large data transformations at scale: serverless SQL pools, dedicated SQL pools, or Spark pools.</li>
</ol>
</li>
<li><p>Azure Databricks</p>
<ol>
<li>Allows you to define your pipelines in a notebook, which you can schedule to run.</li>
<li>Uses Spark clusters, which distribute the compute to transform large amounts of data in less time than when you don‚Äôt use distributed compute</li>
</ol>
</li>
<li><p>Azure Machine Learning</p>
<ol>
<li>Commonly used to train machine learning models, you could also use it to extract, transform, and store the data in preparation for training a machine learning model.</li>
<li>Provides compute clusters, which automatically scale up and down.</li>
<li>However, Azure Synapse Analytics and Azure Databricks offer more scalable compute that allow for transformations to be distributed across compute nodes.</li>
</ol>
</li>
</ul>
<h1 id="A-example-architecture-of-a-data-ingestion-solution"><a href="#A-example-architecture-of-a-data-ingestion-solution" class="headerlink" title="A example architecture of a data ingestion solution"></a>A example architecture of a data ingestion solution</h1><ol>
<li>Extract raw data from its source (like a CRM system or IoT device).</li>
<li>Copy and transform the data with Azure Synapse Analytics.</li>
<li>Store the prepared data in an Azure Blob Storage.</li>
<li>Train the model with Azure Machine Learning.</li>
</ol>
<hr>
<p>References:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/">Design a data ingestion strategy for machine learning projects</a></li>
</ul>
<hr>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>MLops</tag>
        <tag>Azure</tag>
      </tags>
  </entry>
  <entry>
    <title>Sources for building this blog</title>
    <url>/2024/06/01/source-for-building-blog/</url>
    <content><![CDATA[<p>I created this blog using the following websites:</p>
<p><a href="https://xie.infoq.cn/article/ac51ce1f6e9434779c35cbb6c">https://xie.infoq.cn/article/ac51ce1f6e9434779c35cbb6c</a></p>
<p>I use NexT theme. For more information, see: <a href="https://theme-next.js.org/">https://theme-next.js.org/</a>.</p>
<p>I will keep updating this blog for new tricks regarding building the blog.</p>
<h1 id="More-tricks"><a href="#More-tricks" class="headerlink" title="More tricks"></a>More tricks</h1><ul>
<li>Use <code>hexo new draft &quot;your_title&quot;</code> to write a draft (which will not be shown in the website). Then use <code>hexo publish draft &quot;your_title&quot;</code> to publish this draft.</li>
</ul>
<span id="more"></span>
]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>NexT</tag>
      </tags>
  </entry>
</search>
